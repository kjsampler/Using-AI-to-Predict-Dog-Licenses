{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-KDfNxBTzPi"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wSSUO2848QIz"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 83\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\kayce_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ba96ac592cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQVl5OedgPs5"
   },
   "source": [
    "Files to upload: \n",
    "uni_final.csv and df_18_final.csv  \n",
    "Path: Flatiron School > Capstone Project > Dog Licenses > data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPyGKuvIObRI"
   },
   "source": [
    "This kind of model and dataset would lend itself well to a multivariate LSTM model. Let's just take an initial look at the scope of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "jhNR7IfPArIz",
    "outputId": "98925b3f-4951-41fa-8407-fd4d0c901c18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ValidDate</th>\n",
       "      <th>LicenseType</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>DogName</th>\n",
       "      <th>OwnerZip</th>\n",
       "      <th>ExpYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-02 09:40:53</td>\n",
       "      <td>Dog Individual Neutered Male</td>\n",
       "      <td>COCKAPOO</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>CHARLEY</td>\n",
       "      <td>15236</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-02 09:45:25</td>\n",
       "      <td>Dog Senior Citizen or Disability Neutered Male</td>\n",
       "      <td>GER SHEPHERD</td>\n",
       "      <td>BLACK/BROWN</td>\n",
       "      <td>TACODA</td>\n",
       "      <td>15238</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-02 09:47:55</td>\n",
       "      <td>Dog Individual Spayed Female</td>\n",
       "      <td>GER SHEPHERD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>CHARLY</td>\n",
       "      <td>15205</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-02 10:02:33</td>\n",
       "      <td>Dog Individual Spayed Female</td>\n",
       "      <td>LABRADOR RETRIEVER</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>ABBEY</td>\n",
       "      <td>15143</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-02 10:05:50</td>\n",
       "      <td>Dog Individual Female</td>\n",
       "      <td>GER SHORTHAIR POINT</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>CHARLEY</td>\n",
       "      <td>15228</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ValidDate  ... ExpYear\n",
       "0  2014-12-02 09:40:53  ...    2015\n",
       "1  2014-12-02 09:45:25  ...    2015\n",
       "2  2014-12-02 09:47:55  ...    2015\n",
       "3  2014-12-02 10:02:33  ...    2015\n",
       "4  2014-12-02 10:05:50  ...    2015\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('raw_data.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GKUb68rHWc3",
    "outputId": "e82e6bca-f42f-449d-8985-36f4af56b2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146896\n"
     ]
    }
   ],
   "source": [
    "print(len(df_raw['Breed']) + len(df_raw['Color']) + len(df_raw['DogName']) + len(df_raw['OwnerZip']))\n",
    "#If we kepts columns 'as is' and did dummies, this is how many columns we would have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y833_eRPNisQ"
   },
   "source": [
    "A multivariate model seems to be out of the scope of this project. However, an idea for future work would be to use an aggregate of a categorical variable (ie. total PitBulls per month) or a top 10 most popular of a variable to see if we could derive any unexpected insight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VOmcgkgNRVw"
   },
   "source": [
    "# Using an LSTM to predict on a single variable (sum of licenses per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Uzx-AEav2l2"
   },
   "outputs": [],
   "source": [
    "uni_final = pd.read_csv('/content/uni_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "iSq98vDqwCcj",
    "outputId": "9016b25f-9e93-4c72-f1e4-11329187f635"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ValidDate</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-04</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-08</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ValidDate  Sum\n",
       "0  2014-12-02   82\n",
       "1  2014-12-03  232\n",
       "2  2014-12-04  351\n",
       "3  2014-12-05  163\n",
       "4  2014-12-08  337"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv31wmM6wM51"
   },
   "outputs": [],
   "source": [
    "uni_final.set_index('ValidDate', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "vMIopdWywZW1",
    "outputId": "c5d30dbe-402c-41f2-a3ba-73704af84b0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ValidDate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-02</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-03</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-04</th>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-05</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-08</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sum\n",
       "ValidDate      \n",
       "2014-12-02   82\n",
       "2014-12-03  232\n",
       "2014-12-04  351\n",
       "2014-12-05  163\n",
       "2014-12-08  337"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYiPfQ-nwbg1"
   },
   "outputs": [],
   "source": [
    "#Because I am only testing on one variable, should I still scale it? \n",
    "#Scale for sake of timely convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D93Qu32E-1GJ"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "uni_scaled = scaler.fit_transform(uni_final.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ4e1I8YMwWy"
   },
   "source": [
    "#Use series_to_supervise() function from Jason Brownlee via Machine Learning Mastery\n",
    "#Use a lag of 1 to match SARIMA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUfhie-Sye2N"
   },
   "outputs": [],
   "source": [
    "def series_to_supervise(data, n_in = 1, n_out = 1, dropnan = True):\n",
    "  n_vars = 1 if type(data) is list else data.shape[1]\n",
    "  df = pd.DataFrame(data)\n",
    "  cols, names = list(), list()\n",
    "\n",
    "  for i in range(n_in, 0, -1):\n",
    "    cols.append(df.shift(i))\n",
    "    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "  for i in range(0, n_out):\n",
    "    cols.append(df.shift(-i))\n",
    "    if i == 0:\n",
    "      names += [('var%d' % (j+1)) for j in range(n_vars)]\n",
    "    else: \n",
    "      names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "  agg = pd.concat(cols, axis = 1)\n",
    "  agg.columns = names\n",
    "  if dropnan:\n",
    "    agg.dropna(inplace = True)\n",
    "  return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "Thr9pX4yAXRI",
    "outputId": "e6d9c5cf-ec99-4dd9-893a-c21942428027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.037474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037474</td>\n",
       "      <td>0.056695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)      var1\n",
       "1   0.013245  0.037474\n",
       "2   0.037474  0.056695\n",
       "3   0.056695  0.026329\n",
       "4   0.026329  0.054434\n",
       "5   0.054434  0.027298"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_lstm = series_to_supervise(uni_scaled, 1, 1)\n",
    "uni_lstm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isLo3xDvMm30"
   },
   "source": [
    "# Fit data for LSTM model, split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-MBbE1PCNuh"
   },
   "outputs": [],
   "source": [
    "X = uni_lstm['var1(t-1)'].values\n",
    "y = uni_lstm['var1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVZQmUcPA6qY"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCKWC7I1EKmo",
    "outputId": "0a807586-4799-43f9-8150-2e7e87590408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541,) (541,) (232,) (232,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_Xl-OYHMdDV"
   },
   "source": [
    "# Build LSTM model and tune to lowest possible MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQyAArJ4DidA",
    "outputId": "d1006d4f-eda0-46bd-f1fe-aef7d30cdce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232,)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnFjslm2Ecxf",
    "outputId": "a2f899dc-6a74-4f16-d130-b01fd0024705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Time elapsed:  0:00:05.215281\n"
     ]
    }
   ],
   "source": [
    "#Build the LSTM model! \n",
    "now = datetime.datetime.now()\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mse', optimizer = 'sgd', metrics = ['mse'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 50, batch_size = 72, validation_data = (X_test, y_test), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "2mgSEb7iLkeH",
    "outputId": "667af33d-8ec6-4caf-b65c-baadbd48ce22"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrmilvwknz1h"
   },
   "outputs": [],
   "source": [
    "# Looks like it's converging before even 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wy8_BT8wq_HJ",
    "outputId": "db741132-c888-4bd3-adb3-468ee132b71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 1, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 1, 1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTCi1vYsn4Z_",
    "outputId": "6b163eaa-524a-4221-af84-4be98d7db9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of prediction:  507356.01\n"
     ]
    }
   ],
   "source": [
    "# Time to make a prediction\n",
    "yhat = model.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv_yhat = np.concatenate((yhat, X_test[:, 1:]), axis = 1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "inv_y = np.concatenate((y_test, X_test[:, 1:]), axis = 1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]\n",
    "\n",
    "mse = mean_squared_error(inv_y, inv_yhat)\n",
    "print('MSE of prediction: ', np.round(mse, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNWtesYOsU_g"
   },
   "outputs": [],
   "source": [
    "# ARIMA model MSE = 145107.43, LSTM model MSE = 528370.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hCtAcnFvMmA"
   },
   "outputs": [],
   "source": [
    "#Try to get the lowest MSE possible before trying to make a forecast.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MId3DbaxQDVI",
    "outputId": "6c7d9403-9af3-43e0-b91f-6c77e9c3838d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nb_oKWZkzhZY",
    "outputId": "a43f2ab7-9477-4605-9807-ca50e7335d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Time elapsed:  0:00:04.807652\n"
     ]
    }
   ],
   "source": [
    "# Tune the model \n",
    "now = datetime.datetime.now()\n",
    "model_tune = Sequential()\n",
    "model_tune.add(LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model_tune.add(Dense(50, activation = 'tanh'))\n",
    "model_tune.add(Dense(35, activation = 'tanh'))\n",
    "model_tune.add(Dense(20, activation = 'tanh'))\n",
    "model_tune.add(Dense(1))\n",
    "model_tune.compile(loss = 'mse', optimizer = 'sgd', metrics = ['mse'])\n",
    "\n",
    "history_tune = model_tune.fit(X_train, y_train, epochs = 50, batch_size = 72, validation_data = (X_test, y_test), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "F1QnTN_2Plw7",
    "outputId": "40160262-d506-429b-82fe-fa2af82f02ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_tune.history['loss'], label = 'train')\n",
    "plt.plot(history_tune.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_onHtKsQ8Fy"
   },
   "outputs": [],
   "source": [
    "#Still definitely overfitting, even more so now\n",
    "# Original MSE: 0.0164 \n",
    "# Tune MSE: 0.0153 \n",
    "# Keep the 5 layers. Let's look at how to reduce the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTWJmyaxKcrq",
    "outputId": "ae5a837d-7ea3-47cb-c77c-65e75885bc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z4kh9CkKfZK",
    "outputId": "ad5dadec-1bab-4cd9-8d8d-95c94e3bc273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of tuned prediction:  504718.73\n"
     ]
    }
   ],
   "source": [
    "yhat_tune = model_tune.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv_yhat_tune = np.concatenate((yhat_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_yhat_tune = scaler.inverse_transform(inv_yhat_tune)\n",
    "inv_yhat_tune = inv_yhat_tune[:, 0]\n",
    "\n",
    "y_test_tune = y_test.reshape((len(y_test), 1))\n",
    "inv_y_tune = np.concatenate((y_test_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_y_tune = scaler.inverse_transform(inv_y_tune)\n",
    "inv_y_tune = inv_y_tune[:, 0]\n",
    "\n",
    "mse_tune = mean_squared_error(inv_y_tune, inv_yhat_tune)\n",
    "print('MSE of tuned prediction: ', np.round(mse_tune, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGVo-M0XKrms"
   },
   "outputs": [],
   "source": [
    "#LSTM model MSE = 528370.14\n",
    "#Tune 1 = 461669.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fafYD1LfRmSC",
    "outputId": "868816b6-acea-41c2-a4b4-d1eba2f2453a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFilTOZnRCrR",
    "outputId": "704542f3-f3d2-4b54-b39c-6a4c6ac3289b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Time elapsed:  0:00:05.207281\n"
     ]
    }
   ],
   "source": [
    "# Tune the model \n",
    "# Keep 5 layers, try dropouts and maybe an adam optimizer\n",
    "now = datetime.datetime.now()\n",
    "model_tune = Sequential()\n",
    "model_tune.add(LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model_tune.add(Dense(50, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(35, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(20, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(1))\n",
    "model_tune.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "history_tune = model_tune.fit(X_train, y_train, epochs = 50, batch_size = 72, validation_data = (X_test, y_test), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "FoSAiqUOThFS",
    "outputId": "bb975e7a-068e-4c93-d9b4-845b018be6f1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_tune.history['loss'], label = 'train')\n",
    "plt.plot(history_tune.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evqehBSsTqVR"
   },
   "outputs": [],
   "source": [
    "# Original MSE: 0.0164\n",
    "# Tune MSE: 0.0098 \n",
    "# I may go ahead and attempt a forecast with this model and see what the MSE is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVUqnWC-VNbD",
    "outputId": "ac42750b-be3a-44d3-b603-953d5df0f908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aH50fwhuUAL5",
    "outputId": "cb4aaadd-e5c9-4553-f8d3-47a7fd0825b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of tuned prediction:  212194.89\n"
     ]
    }
   ],
   "source": [
    "yhat_tune = model_tune.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv_yhat_tune = np.concatenate((yhat_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_yhat_tune = scaler.inverse_transform(inv_yhat_tune)\n",
    "inv_yhat_tune = inv_yhat_tune[:, 0]\n",
    "\n",
    "y_test_tune = y_test.reshape((len(y_test), 1))\n",
    "inv_y_tune = np.concatenate((y_test_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_y_tune = scaler.inverse_transform(inv_y_tune)\n",
    "inv_y_tune = inv_y_tune[:, 0]\n",
    "\n",
    "mse_tune = mean_squared_error(inv_y_tune, inv_yhat_tune)\n",
    "print('MSE of tuned prediction: ', np.round(mse_tune, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irwfrViPK1Xe"
   },
   "outputs": [],
   "source": [
    "#LSTM model MSE = 528370.14\n",
    "#Tune 1 = 461669.22\n",
    "#Tune 2 = 215734.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFD55Jk2VfaC"
   },
   "outputs": [],
   "source": [
    "# Attempt a few more tuning measures, since this is not taking long to run. \n",
    "# Tune until LSTM < ARIMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kb0oZ24BWfQa",
    "outputId": "7a03c865-a87a-46dd-93bf-03561cf08478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bM11-Un2V2Dx",
    "outputId": "c8f34eb9-796b-41be-acb7-31d2a496ecbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Time elapsed:  0:00:03.229956\n"
     ]
    }
   ],
   "source": [
    "# Try a relu activation to see what happens. \n",
    "# Train for 10 epochs, since it's converging well before 50.\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "model_tune = Sequential()\n",
    "model_tune.add(LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model_tune.add(Dense(50, activation = 'relu'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(35, activation = 'relu'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(20, activation = 'relu'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(1))\n",
    "model_tune.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "history_tune = model_tune.fit(X_train, y_train, epochs = 10, batch_size = 72, validation_data = (X_test, y_test), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_txT1HyWgjx"
   },
   "outputs": [],
   "source": [
    "# Previous tune MSE: 0.0098\n",
    "# Current tune MSE: 0.0114 \n",
    "# Keep the tanh activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JlMpRfgLCLd",
    "outputId": "e1b3a491-a28b-4164-9288-312195f15f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of tuned prediction:  228306.43\n"
     ]
    }
   ],
   "source": [
    "yhat_tune = model_tune.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv_yhat_tune = np.concatenate((yhat_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_yhat_tune = scaler.inverse_transform(inv_yhat_tune)\n",
    "inv_yhat_tune = inv_yhat_tune[:, 0]\n",
    "\n",
    "y_test_tune = y_test.reshape((len(y_test), 1))\n",
    "inv_y_tune = np.concatenate((y_test_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_y_tune = scaler.inverse_transform(inv_y_tune)\n",
    "inv_y_tune = inv_y_tune[:, 0]\n",
    "\n",
    "mse_tune = mean_squared_error(inv_y_tune, inv_yhat_tune)\n",
    "print('MSE of tuned prediction: ', np.round(mse_tune, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAcCKnm0LKtT"
   },
   "outputs": [],
   "source": [
    "#LSTM model MSE = 528370.14\n",
    "#Tune 1 = 461669.22\n",
    "#Tune 2 = 215734.43\n",
    "#Tune 3 = 226372.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GcZ3uMlXXRw",
    "outputId": "da420fe2-d173-4962-999b-acefd36a5a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fX-wj7TRW4nI",
    "outputId": "f93511b0-1283-4c8b-c4dc-f07a9c4658aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Time elapsed:  0:00:03.569844\n"
     ]
    }
   ],
   "source": [
    "# Try changing batch size \n",
    "now = datetime.datetime.now()\n",
    "model_tune = Sequential()\n",
    "model_tune.add(LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model_tune.add(Dense(50, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(35, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(20, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(1))\n",
    "model_tune.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "history_tune = model_tune.fit(X_train, y_train, epochs = 10, batch_size = 20, validation_data = (X_test, y_test), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBddyRfjXaRR"
   },
   "outputs": [],
   "source": [
    "# Previous tune MSE: 0.0098\n",
    "# Current tune MSE: 0.0094\n",
    "# Batch size did not make a significant difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMB0_kcXLYWz",
    "outputId": "0508c256-8e8d-4aa8-925a-e62d43e8caea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of tuned prediction:  245863.14\n"
     ]
    }
   ],
   "source": [
    "yhat_tune = model_tune.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv_yhat_tune = np.concatenate((yhat_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_yhat_tune = scaler.inverse_transform(inv_yhat_tune)\n",
    "inv_yhat_tune = inv_yhat_tune[:, 0]\n",
    "\n",
    "y_test_tune = y_test.reshape((len(y_test), 1))\n",
    "inv_y_tune = np.concatenate((y_test_tune, X_test[:, 1:]), axis = 1)\n",
    "inv_y_tune = scaler.inverse_transform(inv_y_tune)\n",
    "inv_y_tune = inv_y_tune[:, 0]\n",
    "\n",
    "mse_tune = mean_squared_error(inv_y_tune, inv_yhat_tune)\n",
    "print('MSE of tuned prediction: ', np.round(mse_tune, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmkSfoASLaGb"
   },
   "outputs": [],
   "source": [
    "#LSTM model MSE = 528370.14\n",
    "#Tune 1 = 461669.22\n",
    "#Tune 2 = 215734.43\n",
    "#Tune 3 = 226372.89\n",
    "#Tune 4 = 233653.45\n",
    "\n",
    "#Keep tune 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11oDsS9rMrSM",
    "outputId": "98cd22ae-f0ff-44e9-b6da-b2ee1bb43480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 1) (541,) (232, 1, 1) (232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iq2LpVm9MZxd",
    "outputId": "2520b740-9003-45ef-b036-855876752d63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Time elapsed:  0:00:03.310651\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "model_tune = Sequential()\n",
    "model_tune.add(LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model_tune.add(Dense(50, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(35, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(20, activation = 'tanh'))\n",
    "model_tune.add(Dropout(0.3))\n",
    "model_tune.add(Dense(1))\n",
    "model_tune.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "history_tune = model_tune.fit(X_train, y_train, epochs = 10, batch_size = 72, validation_data = (X_test, y_test), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBhcYpRuiMtT"
   },
   "outputs": [],
   "source": [
    "# Increase lags. It's not a direct comparison to ARIMA, but it will most likely increase the accuracy of the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "zaVk-N3cimCx",
    "outputId": "a365161e-70f2-4471-e76b-810f609e6478"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.037474</td>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037474</td>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.017606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.019706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var1(t-2)  var1(t-1)      var1\n",
       "3   0.013245   0.037474   0.056695  0.026329\n",
       "4   0.037474   0.056695   0.026329  0.054434\n",
       "5   0.056695   0.026329   0.054434  0.027298\n",
       "6   0.026329   0.054434   0.027298  0.017606\n",
       "7   0.054434   0.027298   0.017606  0.019706"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_lag = series_to_supervise(uni_scaled, 3, 1)\n",
    "three_lag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkxbyT99jZGT"
   },
   "outputs": [],
   "source": [
    "X_3 = three_lag.drop(['var1'], axis = 1).values\n",
    "y_3 = three_lag['var1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuyrWaOojx0b"
   },
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRL4lLOQlWIK",
    "outputId": "d0a93f93-0b90-42e8-b773-3dfca1a436f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539, 3, 1) (539,) (232, 3, 1) (232,)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (1), features (1)\n",
    "X_train_3 = X_train_3.reshape((X_train_3.shape[0], 3, 1))\n",
    "X_test_3 = X_test_3.reshape((X_test.shape[0], 3, 1))\n",
    "print(X_train_3.shape, y_train_3.shape, X_test_3.shape, y_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEn5NWdIllE9",
    "outputId": "1cd5a3ee-69f7-4f0b-a905-dadb0e87d922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0075 - val_mse: 0.0075\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "model_3 = Sequential()\n",
    "model_3.add(LSTM(50, input_shape = (X_train_3.shape[1], X_train_3.shape[2])))\n",
    "model_3.add(Dense(50, activation = 'tanh'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(35, activation = 'tanh'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(20, activation = 'tanh'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(1))\n",
    "model_3.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "history_3 = model_3.fit(X_train_3, y_train_3, epochs = 10, batch_size = 72, validation_data = (X_test_3, y_test_3), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r_fgjenl8Ip"
   },
   "outputs": [],
   "source": [
    "#Single lag MSE: 0.0094\n",
    "#3 day lag MSE: 0.0066\n",
    "# I think I'll take a win where I can get it. There's always the opportunity to keep tuning, but I think this is where i'll call it for this project. \n",
    "# Now for a forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_oIezjomQwh"
   },
   "outputs": [],
   "source": [
    "# ARIMA model MSE = 145107.43, tuned LSTM model MSE = 217163.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apdREr1omdqx",
    "outputId": "f676a122-7aa7-4716-e6f4-57500382ae69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539, 3, 1) (539,) (232, 3, 1) (232,)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (3), features (1)\n",
    "X_train_3 = X_train_3.reshape((X_train_3.shape[0], 3, 1))\n",
    "X_test_3 = X_test_3.reshape((X_test.shape[0], 3, 1))\n",
    "print(X_train_3.shape, y_train_3.shape, X_test_3.shape, y_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvQbT8obmYnZ",
    "outputId": "1c4e3f1d-c380-44f6-9e68-7c5c592e8de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Lag 3 prediction:  288473.52\n"
     ]
    }
   ],
   "source": [
    "yhat_3 = model_3.predict(X_test_3)\n",
    "X_test_3 = X_test_3.reshape((X_test_3.shape[0], 3))\n",
    "inv_yhat_3 = np.concatenate((yhat_3, X_test_3[:, 1:]), axis = 1)\n",
    "inv_yhat_3 = scaler.inverse_transform(inv_yhat_3)\n",
    "inv_yhat_3 = inv_yhat_3[:, 0]\n",
    "\n",
    "y_test_3 = y_test_3.reshape((len(y_test_3), 1))\n",
    "inv_y_3 = np.concatenate((y_test_3, X_test_3[:, 1:]), axis = 1)\n",
    "inv_y_3 = scaler.inverse_transform(inv_y_3)\n",
    "inv_y_3 = inv_y_3[:, 0]\n",
    "\n",
    "mse_3 = mean_squared_error(inv_y_3, inv_yhat_3)\n",
    "print('MSE of Lag 3 prediction: ', np.round(mse_3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R75AGFZOnRdC"
   },
   "outputs": [],
   "source": [
    "#Well that didn't go as expected... \n",
    "# ARIMA model MSE = 145107.43, tuned LSTM model MSE = 217163.67, Lag 3 LSTM MSE = 326862.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "7N-UDo6Spzth",
    "outputId": "aae1b857-0b08-4c84-cba3-10a24a2c75e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.037474</td>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.037474</td>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.017606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056695</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.019706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>0.017768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>0.019545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-5)  var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)      var1\n",
       "5   0.013245   0.037474   0.056695   0.026329   0.054434  0.027298\n",
       "6   0.037474   0.056695   0.026329   0.054434   0.027298  0.017606\n",
       "7   0.056695   0.026329   0.054434   0.027298   0.017606  0.019706\n",
       "8   0.026329   0.054434   0.027298   0.017606   0.019706  0.017768\n",
       "9   0.054434   0.027298   0.017606   0.019706   0.017768  0.019545"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try lag of 5, choose best from that. \n",
    "five_lag = series_to_supervise(uni_scaled, 5, 1)\n",
    "five_lag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3IDxLUGICWT"
   },
   "outputs": [],
   "source": [
    "X_5 = five_lag.drop(['var1'], axis = 1).values\n",
    "y_5 = five_lag['var1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "padSkTGLH4wT"
   },
   "outputs": [],
   "source": [
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X_5, y_5, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nOCT1nkILer",
    "outputId": "cf944142-82ae-46b1-e6ec-d135a5310aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 5, 1) (538,) (231, 5, 1) (231,)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (5), features (1)\n",
    "X_train_5 = X_train_5.reshape((X_train_5.shape[0], 5, 1))\n",
    "X_test_5 = X_test_5.reshape((X_test_5.shape[0], 5, 1))\n",
    "print(X_train_5.shape, y_train_5.shape, X_test_5.shape, y_test_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHjhDFIFIeGT",
    "outputId": "b8baa10c-cd56-400c-fc68-a05b872ac5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Time elapsed:  0:00:04.213750\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "model_5 = Sequential()\n",
    "model_5.add(LSTM(50, input_shape = (X_train_5.shape[1], X_train_5.shape[2])))\n",
    "model_5.add(Dense(50, activation = 'tanh'))\n",
    "model_5.add(Dropout(0.3))\n",
    "model_5.add(Dense(35, activation = 'tanh'))\n",
    "model_5.add(Dropout(0.3))\n",
    "model_5.add(Dense(20, activation = 'tanh'))\n",
    "model_5.add(Dropout(0.3))\n",
    "model_5.add(Dense(1))\n",
    "model_5.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "history_5 = model_5.fit(X_train_5, y_train_5, epochs = 10, batch_size = 20, validation_data = (X_test_5, y_test_5), verbose = True, shuffle = False)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time elapsed: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugt8PiRnIudD"
   },
   "outputs": [],
   "source": [
    "#Single lag MSE: 0.0094\n",
    "#3 day lag MSE: 0.0066\n",
    "#5 day lag MSE: 0.0075\n",
    "#Higher than 3 day lag, but I'll go ahead and run a forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfWZrMbvJcdz",
    "outputId": "5efe47a0-a30e-42f1-e78f-92fd36c76e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 5, 1) (538,) (231, 5, 1) (231,)\n"
     ]
    }
   ],
   "source": [
    "#Reshape into a 3D that LSTM expects\n",
    "#Inputs, timesteps (5), features (1)\n",
    "X_train_5 = X_train_5.reshape((X_train_5.shape[0], 5, 1))\n",
    "X_test_5 = X_test_5.reshape((X_test_5.shape[0], 5, 1))\n",
    "print(X_train_5.shape, y_train_5.shape, X_test_5.shape, y_test_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3G57capJGAL",
    "outputId": "90dab011-f65a-440c-9085-8eed6eae52f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Lag 5 prediction:  150148.29\n"
     ]
    }
   ],
   "source": [
    "yhat_5 = model_5.predict(X_test_5)\n",
    "X_test_5 = X_test_5.reshape((X_test_5.shape[0], 5))\n",
    "inv_yhat_5 = np.concatenate((yhat_5, X_test_5[:, 1:]), axis = 1)\n",
    "inv_yhat_5 = scaler.inverse_transform(inv_yhat_5)\n",
    "inv_yhat_5 = inv_yhat_5[:, 0]\n",
    "\n",
    "y_test_5 = y_test_5.reshape((len(y_test_5), 1))\n",
    "inv_y_5 = np.concatenate((y_test_5, X_test_5[:, 1:]), axis = 1)\n",
    "inv_y_5 = scaler.inverse_transform(inv_y_5)\n",
    "inv_y_5 = inv_y_5[:, 0]\n",
    "\n",
    "mse_5 = mean_squared_error(inv_y_5, inv_yhat_5)\n",
    "print('MSE of Lag 5 prediction: ', np.round(mse_5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1awCTmeJjsD"
   },
   "outputs": [],
   "source": [
    "# ARIMA model MSE = 145107.43\n",
    "#tuned LSTM model MSE = 217163.67\n",
    "#Lag 3 LSTM MSE = 314797.98\n",
    "#Lag 5 LSTM MSE = 166632.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_InEUhhoJzO6"
   },
   "outputs": [],
   "source": [
    "#I will be using this tuned model for my future predictions. It's not great, but there is always opportunity to improve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iItS7OBvBNwQ",
    "outputId": "e580e616-6dbd-4b58-e257-b4795275173d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 5, 1) (538,) (231, 5, 1) (231, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_5 = X_train_5.reshape((X_train_5.shape[0], 5, 1))\n",
    "X_test_5 = X_test_5.reshape((X_test_5.shape[0], 5, 1))\n",
    "print(X_train_5.shape, y_train_5.shape, X_test_5.shape, y_test_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5VJ3twwLwbk",
    "outputId": "ed6e2d1c-4783-4975-8f42-f61215f16373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: final_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(LSTM(50, input_shape = (X_train_5.shape[1], X_train_5.shape[2])))\n",
    "model_5.add(Dense(50, activation = 'tanh'))\n",
    "model_5.add(Dropout(0.3))\n",
    "model_5.add(Dense(35, activation = 'tanh'))\n",
    "model_5.add(Dropout(0.3))\n",
    "model_5.add(Dense(20, activation = 'tanh'))\n",
    "model_5.add(Dropout(0.3))\n",
    "model_5.add(Dense(1))\n",
    "model_5.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse'])\n",
    "model_5.fit(X_train_5, y_train_5, epochs = 10, batch_size = 20, validation_data = (X_test_5, y_test_5), verbose = True, shuffle = False)\n",
    "model_5.save('final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duQYMAS-K8MB"
   },
   "source": [
    "# Write a function to recursively forecast a given number of steps into the future, and return a dataframe with forecasted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qxIeIZz_0PP"
   },
   "outputs": [],
   "source": [
    "#Create output df\n",
    "output = pd.DataFrame({'Valid Date': pd.date_range(start = '2017-12-22', end = '2018-12-20', freq = 'B')})\n",
    "output = output[(output['Valid Date'] != '2017-12-25') &\n",
    "                (output['Valid Date'] != '2018-01-01') &\n",
    "                (output['Valid Date'] != '2018-01-15') &\n",
    "                (output['Valid Date'] != '2018-02-19') &\n",
    "                (output['Valid Date'] != '2018-05-28') &\n",
    "                (output['Valid Date'] != '2018-07-04') &\n",
    "                (output['Valid Date'] != '2018-09-03') &\n",
    "                (output['Valid Date'] != '2018-11-12') &\n",
    "                (output['Valid Date'] != '2018-11-22')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aqy3V0rwHihl"
   },
   "outputs": [],
   "source": [
    "#Write prediction function\n",
    "def predict_values(training_data, output):\n",
    "  ''' A function that takes in training data and uses a tuned LSTM neural \n",
    "  network to recursively predict data for a given number of steps.\n",
    "\n",
    "  Inputs: training_data: The last 5 points of the models training set\n",
    "    output: user provided dataframe formatted with a desired time period to be predicted\n",
    "    as a pd.TimeStamp \n",
    "  Returns: The output parameter with a scaled prediction and unscaled prediction column \n",
    "  appended'''\n",
    "\n",
    "  predictions = []\n",
    "  predictions.append(training_data)\n",
    "  x_array = np.array(predictions)\n",
    "  x_array = x_array.reshape(1, 5, 1)\n",
    "#Generate predictions\n",
    "  model = load_model('final_model')\n",
    "  for n in range(len(output)):\n",
    "    pred = model.predict(x_array)\n",
    "    x_array = np.append(x_array, pred)\n",
    "    predictions.append(pred)\n",
    "\n",
    "    x_array = x_array[-5:].reshape(1, 5, 1)\n",
    "\n",
    "#Add predictions to output df, unlist the values\n",
    "  predictions = predictions[1:]\n",
    "  pred_list = []\n",
    "  for n in range(len(output)):\n",
    "    pred_list.append(predictions[n].tolist())\n",
    "\n",
    "  unlisted = []\n",
    "  for n in range(len(pred_list)):\n",
    "    var = pred_list[n]\n",
    "    var = var[0]\n",
    "    unlisted.append(var)\n",
    "\n",
    "  output['Scaled Prediction'] = unlisted\n",
    "\n",
    "#Unscale predicted value\n",
    "  unlisted_array = np.array(unlisted)\n",
    "  unlisted_array = unlisted_array.reshape(-1, 1)\n",
    "  output['Predicted Value'] = scaler.inverse_transform(unlisted_array)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NyvMvw9Hk77"
   },
   "outputs": [],
   "source": [
    "year_one = predict_values(X_train[-5:], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7Pjgq4bH0mc"
   },
   "outputs": [],
   "source": [
    "year_one = year_one.set_index('Valid Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "PtilAnWbBTN_",
    "outputId": "60251483-ef15-48b1-c31c-699d8f0dcd54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted Licenses Dispensed')"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = year_one['Predicted Value'].plot()\n",
    "fig.set_title('Predicted Value')\n",
    "fig.set_xlabel('Valid Date')\n",
    "fig.set_ylabel('Predicted Licenses Dispensed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbLqnE4_HWuG"
   },
   "outputs": [],
   "source": [
    "#There's a lot going on in the first 3 months, but after that it converges on itself\n",
    "#I think that part of the issue here is that 251 steps is just too much for this kind of model\n",
    "#I will still calculate the MSE, just out of curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aWq8LRUHxHF"
   },
   "outputs": [],
   "source": [
    "#To keep it consistent, we will set all negative values to 0\n",
    "year_one.loc[year_one['Predicted Value'] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ch0aNXVITBM"
   },
   "outputs": [],
   "source": [
    "df_18 = pd.read_csv('df_18_final.csv')\n",
    "df_18 = df_18.set_index('ValidDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGLm7Zv-JKmO",
    "outputId": "b4d79caa-587e-4ebb-b5d7-42ca110251f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forecast MSE is 142611.59\n"
     ]
    }
   ],
   "source": [
    "mse = ((year_one['Predicted Value'] - df_18['Sum']) ** 2).mean()\n",
    "print('The forecast MSE is {}'.format(round(mse, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHqNG6ZYT5H8"
   },
   "source": [
    "# Conclusions/ Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNUWgWF6Pzgd"
   },
   "source": [
    "Despite that scary looking graph, this actually performs better than our SARIMA forecast, which had an MSE of 145107.43. This model is not too shabby. And has the benefit that we didn't have to gridsearch for the best pdq like the SARIMA. It should definitely be used for a shorter amount of steps though, as it would seem the accuracy really starts to drop off as the model converges on itself.  \n",
    "Some ideas for future work:  \n",
    "* I would love to run a couple multivariate models and see if the categorical variables influence the forecast somehow.  \n",
    "* As with most neural networks, you could spend weeks just tuning this. If there were more time, I would like to keep tweaking the final model and seeing just how low we can get the MSE. Even though this is the lowest one, it's still pretty high. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Flatiron School Capstone- LSTM Time Series.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
